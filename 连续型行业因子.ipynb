{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.optimize as sco\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df.set_index(\"code\",inplace=True)\n",
    "\n",
    "#去除st股票\n",
    "st_stock=list(pd.read_csv(\"st_stocks.csv\")[\"code\"])\n",
    "alpha_df.drop(st_stock,inplace=True)\n",
    "\n",
    "#去除新股和停牌股\n",
    "grouped=alpha_df.groupby(\"datetime\")\n",
    "date_list=list(alpha_df[\"datetime\"].drop_duplicates())\n",
    "code_list=list(alpha_df.index.drop_duplicates())\n",
    "join=set(code_list)\n",
    "union=set(code_list)\n",
    "for date in date_list:\n",
    "    df=grouped.get_group(date)\n",
    "    stock_set=set(df.index)\n",
    "    join=stock_set&join\n",
    "    union=stock_set|union\n",
    "other_list=list(union-join)\n",
    "alpha_df.drop(other_list,inplace=True)\n",
    "\n",
    "alpha_df.to_csv(\"growth_factor.csv\",index_label=\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#数据处理\n",
    "change_data_1=pd.read_csv(\"change.csv\",dtype={\"stock_code\":str})\n",
    "change_data_2=pd.read_csv(\"change_2.csv\",dtype={\"stock_code\":str})\n",
    "change_data=pd.concat([change_data_1,change_data_2])\n",
    "\n",
    "change_data.rename(columns={\"stock_code\":\"code\",\"trade_date\":\"datetime\"},inplace=True)\n",
    "change_data[\"datetime\"]=change_data[\"datetime\"].apply(lambda x:x[0:10])\n",
    "change_data[\"code\"]=change_data[\"code\"].apply(lambda x:x+\".SH\" if x[0]==\"6\" else x+\".SZ\")\n",
    "\n",
    "change_data.sort_values(by=[\"datetime\",\"code\"],ascending=[True,True],inplace=True)\n",
    "\n",
    "change_data.set_index(\"code\",inplace=True)\n",
    "\n",
    "grouped=change_data.groupby(\"datetime\")\n",
    "date_list=list(change_data[\"datetime\"].drop_duplicates())\n",
    "code_list=list(change_data.index.drop_duplicates())\n",
    "join=set(code_list)\n",
    "union=set(code_list)\n",
    "for date in date_list:\n",
    "    df=grouped.get_group(date)\n",
    "    stock_set=set(df.index)\n",
    "    join=stock_set&join\n",
    "    union=stock_set|union\n",
    "other_list=list(union-join)\n",
    "change_data.drop(other_list,inplace=True)\n",
    "\n",
    "drop_list=random.sample(list(join),1135)\n",
    "change_data.drop(drop_list,inplace=True)\n",
    "\n",
    "change_data.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"data_needs.csv\")\n",
    "date=list(data[\"datetime\"].drop_duplicates())[-1]\n",
    "df=data.groupby(\"datetime\").get_group(date)\n",
    "dic=dict(zip(df[\"code\"],df[\"industry_code\"]))\n",
    "change_data[\"industry_code\"]=change_data[\"code\"].apply(lambda x:dic.get(x,0))\n",
    "\n",
    "drop_list=list(set(change_data[\"code\"][change_data[\"industry_code\"]==0]))\n",
    "change_data.set_index(\"code\",inplace=True)\n",
    "change_data.drop(drop_list,inplace=True)\n",
    "change_data.reset_index(inplace=True)\n",
    "\n",
    "stock_ret_df=change_data.pivot_table(\"change_rate\",index=\"datetime\",columns=\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入各行业日频收益率数据并进行形式上的处理\n",
    "data_df=pd.read_csv(\"indus_ret.csv\")\n",
    "data_df.sort_values(by=[\"trade_date\",\"industry_code\"],ascending=[\"True\",\"True\"],inplace=True)\n",
    "\n",
    "data_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "indus_ret_df=data_df.pivot_table(\"change_rate\",index=\"trade_date\",columns=\"industry_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(index,stock_ret,indus_ret_df):\n",
    "    \n",
    "    half_time=60\n",
    "    lamd=pow(0.5,1/half_time)\n",
    "    weight=np.power(lamd,np.arange(252))[::-1]\n",
    "    weight=weight/np.sum(weight)\n",
    "    \n",
    "    indus_ret_df_1=pd.DataFrame(zjh(np.array(indus_ret_df.iloc[index,:])))\n",
    "    \n",
    "    beta_ls=[]\n",
    "    for indus in indus_ret_df_1.columns:\n",
    "        x=np.array(indus_ret_df_1[indus])\n",
    "        y=np.array(stock_ret.iloc[index])\n",
    "        x=sm.add_constant(x)\n",
    "        y=np.dot(np.diag(weight),y)\n",
    "        x=np.dot(np.diag(weight),x)\n",
    "        try:\n",
    "            model=sm.OLS(y,x)\n",
    "            re=model.fit()\n",
    "            beta_ls.append(re.params[1])\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    beta_arr=np.array(beta_ls)\n",
    "\n",
    "    beta_arr=np.abs(beta_arr)/np.sum(np.abs(beta_arr))\n",
    "    \n",
    "    beta_df.loc[(stock_ret.index[int(index[-1])],stock_code)]=beta_arr\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zjh(arr):\n",
    "    arr_t=arr.transpose()\n",
    "\n",
    "    #计算重叠矩阵\n",
    "    overlap_matrix=np.dot(arr_t,arr)\n",
    "    overlap_matrix=(overlap_matrix.T+overlap_matrix)/2\n",
    "    #计算特征值、特征向量\n",
    "    eigvalue,eigvector=np.linalg.eig(overlap_matrix)\n",
    "\n",
    "    #处理对角矩阵\n",
    "    eigvalue=eigvalue**(-0.5)\n",
    "    DiagMat=np.diag(eigvalue)\n",
    "\n",
    "    #计算最终正交矩阵\n",
    "    tmp=np.dot(eigvector,DiagMat)\n",
    "    TSMat=np.dot(tmp,eigvector.transpose())\n",
    "    OrthMat=np.dot(arr,TSMat)\n",
    "    \n",
    "    return OrthMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df=pd.DataFrame(columns=indus_ret_df.columns,index=pd.MultiIndex.from_product([stock_ret_df.index[251::21],stock_ret_df.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_num=stock_ret_df.index\n",
    "index_se=pd.Series(np.arange(len(date_num)))\n",
    "\n",
    "for stock_code in stock_ret_df.columns:\n",
    "    print(stock_code)\n",
    "    stock_ret=stock_ret_df[stock_code]\n",
    "    \n",
    "    for i in range(251,len(date_num),21):\n",
    "        fun(range(i-251,i+1),stock_ret,indus_ret_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "indus_dict=dict(zip(np.arange(28),indus_ret_df.columns))\n",
    "beta_df[\"max_indus\"]=beta_df.iloc[:,0:28].apply(lambda x:np.argmax(np.array(x)),axis=1)\n",
    "beta_df[\"max_indus\"]=beta_df[\"max_indus\"].map(indus_dict)\n",
    "\n",
    "beta_df.reset_index(inplace=True)\n",
    "beta_df[\"real_indus\"]=beta_df[\"level_1\"].map(dic)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df.reset_index(inplace=True)\n",
    "beta_df.rename(columns={\"level_0\":\"datetime\",\"level_1\":\"code\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df=pd.read_csv(\"equal_weight ZScore_1.csv\")\n",
    "\n",
    "code_list=list(alpha_df[\"code\"].drop_duplicates())\n",
    "alpha_df.set_index(\"code\",inplace=True)\n",
    "\n",
    "drop_code=set(code_list)-set(stock_ret_df.columns)\n",
    "alpha_df.drop(drop_code,inplace=True)\n",
    "\n",
    "alpha_df.reset_index()\n",
    "\n",
    "alpha_df.sort_values(by=[\"datetime\",\"code\"],ascending=[True,True],inplace=True)\n",
    "\n",
    "alpha_df=pd.merge(alpha_df,beta_df,on=[\"datetime\",\"code\"])\n",
    "alpha_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mcap_data_1=pd.read_csv(\"mcap.csv\",dtype={\"stock_code\":str})\n",
    "mcap_data_2=pd.read_csv(\"mcap_2.csv\",dtype={\"stock_code\":str})\n",
    "mcap_data=pd.concat([mcap_data_1,mcap_data_2])\n",
    "\n",
    "mcap_data.rename(columns={\"stock_code\":\"code\",\"trade_date\":\"datetime\"},inplace=True)\n",
    "mcap_data[\"datetime\"]=mcap_data[\"datetime\"].apply(lambda x:x[0:10])\n",
    "mcap_data[\"code\"]=mcap_data[\"code\"].apply(lambda x:x+\".SH\" if x[0]==\"6\" else x+\".SZ\")\n",
    "\n",
    "new_alpha_df=pd.merge(alpha_df,mcap_data,on=[\"datetime\",\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ret_df=stock_ret_df\n",
    "\n",
    "for code in ret_df.columns:\n",
    "    ret_df[code+\"_In_change\"]=np.array(np.log(1+ret_df[code]/100))[::-1]\n",
    "    ret_df[code+\"_21d_ret\"]=(np.array(np.exp(ret_df[code+\"_In_change\"].rolling(21).apply(np.sum)))[::-1]-1)*100\n",
    "    ret_df[code+\"_21d_ret\"]=ret_df[code+\"_21d_ret\"].shift(-1)\n",
    "    del ret_df[code+\"_In_change\"]\n",
    "\n",
    "stock_num=len(stock_ret_df.columns)\n",
    "df=pd.DataFrame(stock_ret_df.iloc[:,int(stock_num/2):stock_num]).stack()\n",
    "\n",
    "df=df.reset_index()\n",
    "df[\"code\"]=df[\"code\"].apply(lambda x:x[0:9])\n",
    "new_alpha_df=pd.merge(new_alpha_df,df,on=[\"datetime\",\"code\"])\n",
    "new_alpha_df.rename(columns={0:\"21d_ret\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz500=pd.read_csv(\"zz500.csv\")\n",
    "zz500[\"_In_change\"]=np.array(np.log(1+zz500[\"change_rate\"]/100))[::-1]\n",
    "zz500[\"_21d_ret\"]=(np.array(np.exp(zz500[\"_In_change\"].rolling(21).apply(np.sum)))[::-1]-1)*100\n",
    "zz500[\"_21d_ret\"]=zz500[\"_21d_ret\"].shift(-1)\n",
    "\n",
    "\n",
    "zz500.rename(columns={\"_21d_ret\":\"mkt_ret\",\"trade_date\":\"datetime\"},inplace=True)\n",
    "zz500[\"datetime\"]=zz500[\"datetime\"].apply(lambda x:x[0:10])\n",
    "del zz500[\"index_code\"]\n",
    "del zz500[\"_In_change\"]\n",
    "del zz500[\"change_rate\"]\n",
    "new_alpha_df=pd.merge(new_alpha_df,zz500,on=\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_handle(mat):\n",
    "    for i in range(mat.shape[1]):\n",
    "        arr = np.array(mat[:,i])\n",
    "        M = np.median(arr)\n",
    "        MAD = 1.483 * np.median(np.abs(arr - M))\n",
    "        arr[arr > M + 3 * MAD] = M + 3 * MAD\n",
    "        arr[arr < M - 3 * MAD] = M - 3 * MAD\n",
    "        mat[:,i] = arr\n",
    "            \n",
    "    for i in range(mat.shape[1]):\n",
    "        arr = np.array(mat[:,i])\n",
    "        weight = np.array(len(arr) * [1 / len(arr)])\n",
    "        weighted_avarage = np.dot(weight.T, arr)\n",
    "        arr = (arr - weighted_avarage) / arr.std()\n",
    "        mat[:,i] = arr\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_alpha_df=pd.read_csv(\"indus_factor_comp_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df=raw_alpha_df\n",
    "alpha_df.set_index(\"datetime\",inplace=True)\n",
    "\n",
    "grouped=alpha_df.groupby(\"datetime\")\n",
    "factor_list=['BETA','RSTR','LNCAP','ETOP','DASTD','EGRO','BTOP','DTOA','STOM']\n",
    "alpha_df[\"R_square_1\"]=np.nan\n",
    "alpha_df[\"R_square_2\"]=np.nan\n",
    "\n",
    "for date in date_list[251:-30:42]:\n",
    "    df=grouped.get_group(date)\n",
    "\n",
    "    mktv=np.array(df[\"mcap\"])\n",
    "    mktv_pct=np.sqrt(mktv)/np.sum(np.sqrt(mktv))\n",
    "    weight=mktv_pct**(0.5)\n",
    "    \n",
    "    y=np.array(df[\"21d_ret\"]-df[\"mkt_ret\"])\n",
    "    y=np.dot(np.diag(weight),y)\n",
    "    \n",
    "    #行业哑变量回归\n",
    "    indus_factor=np.array(sm.categorical(np.array(df[\"industry_code\"])))[:, 1:]\n",
    "    style_factor=np.array(df[factor_list])\n",
    "    style_factor=data_handle(zjh(style_factor))\n",
    "    x=np.column_stack([indus_factor,style_factor])\n",
    "    x=np.dot(np.diag(weight),x)\n",
    "    \n",
    "    model=sm.OLS(y,x)\n",
    "    result=model.fit()\n",
    "    R_square_1=result.rsquared_adj\n",
    "    alpha_df[\"R_square_1\"][date]=R_square_1\n",
    "    \n",
    "    #行业连续变量回归\n",
    "    indus_factor=np.array(df[[str(x) for x in indus_ret_df.columns]])\n",
    "    style_factor=np.array(df[factor_list])\n",
    "    style_factor=data_handle(zjh(style_factor))\n",
    "    x=np.column_stack([indus_factor,style_factor])\n",
    "    x=np.dot(np.diag(weight),x)\n",
    "    \n",
    "    model=sm.OLS(y,x)\n",
    "    result=model.fit()\n",
    "    R_square_2=result.rsquared_adj\n",
    "    alpha_df[\"R_square_2\"][date]=R_square_2\n",
    "    \n",
    "alpha_df.reset_index(inplace=True) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=alpha_df.groupby(\"datetime\").agg(np.mean)[[\"R_square_1\",\"R_square_2\"]]\n",
    "df_1.rename(columns={\"R_square_1\":\"dummy_indus_vari\",\"R_square_2\":\"beta_indus_vari\"},inplace=True)\n",
    "\n",
    "ax = df_1.plot() \n",
    "fig = ax.get_figure()\n",
    "fig.savefig('fig_1.jpg',dpi=500)\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=alpha_df.groupby(\"datetime\").agg(np.mean)[[\"R_square_1\",\"R_square_2\"]]\n",
    "df_2.rename(columns={\"R_square_1\":\"dummy_indus_vari\",\"R_square_2\":\"beta_indus_vari_half_time\"},inplace=True)\n",
    "df_2.dropna(inplace=True)\n",
    "\n",
    "\n",
    "ax = df_2.plot() \n",
    "fig = ax.get_figure()\n",
    "fig.savefig('fig_2.jpg',dpi=500)\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_1,df_2],axis=1)\n",
    "ax = df.plot() \n",
    "fig = ax.get_figure()\n",
    "fig.savefig('fig_3.jpg',dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
