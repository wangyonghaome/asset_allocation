{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#从文件中读取数据\r\n",
    "alpha_df_17=pd.read_csv(\"factor_data.csv\",dtype={\"stock_code\":str})\r\n",
    "alpha_df_16=pd.read_csv(\"factor_data_16.csv\",dtype={\"stock_code\":str})\r\n",
    "alpha_df_15=pd.read_csv(\"factor_data_15.csv\",dtype={\"stock_code\":str})\r\n",
    "alpha_df_14=pd.read_csv(\"factor_data_14.csv\",dtype={\"stock_code\":str})\r\n",
    "alpha_df_13=pd.read_csv(\"factor_data_13.csv\",dtype={\"stock_code\":str})\r\n",
    "alpha_df_12=pd.read_csv(\"factor_data_12.csv\",dtype={\"stock_code\":str})\r\n",
    "alpha_df=pd.concat([alpha_df_17,alpha_df_16,alpha_df_15,alpha_df_14,alpha_df_13,alpha_df_12])\r\n",
    "\r\n",
    "alpha_df.rename(columns={\"date\":\"datetime\",\"stock_code\":\"code\"},inplace=True)\r\n",
    "alpha_df[\"code\"]=alpha_df[\"code\"].apply(lambda x:x+\".SH\" if x[0]==\"6\" else x+\".SZ\")\r\n",
    "alpha_df.sort_values(by=[\"datetime\",\"code\"],ascending=[False,True],inplace=True)\r\n",
    "\r\n",
    "#添加上股票的行业信息\r\n",
    "data=pd.read_csv(\"data_needs.csv\")\r\n",
    "date=list(data[\"datetime\"].drop_duplicates())[-1]\r\n",
    "df=data.groupby(\"datetime\").get_group(date)\r\n",
    "dic=dict(zip(df[\"code\"],df[\"industry_code\"]))\r\n",
    "alpha_df[\"industry_code\"]=alpha_df[\"code\"].apply(lambda x:dic.get(x,0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha_df.set_index(\"code\",inplace=True)\r\n",
    "\r\n",
    "#去除st股票\r\n",
    "st_stock=list(pd.read_csv(\"st_stocks.csv\")[\"code\"])\r\n",
    "alpha_df.drop(st_stock,inplace=True)\r\n",
    "\r\n",
    "#去除新股和停牌股\r\n",
    "grouped=alpha_df.groupby(\"datetime\")\r\n",
    "date_list=list(alpha_df[\"datetime\"].drop_duplicates())\r\n",
    "code_list=list(alpha_df.index.drop_duplicates())\r\n",
    "join=set(code_list)\r\n",
    "union=set(code_list)\r\n",
    "for date in date_list:\r\n",
    "    df=grouped.get_group(date)\r\n",
    "    stock_set=set(df.index)\r\n",
    "    join=stock_set&join\r\n",
    "    union=stock_set|union\r\n",
    "other_list=list(union-join)\r\n",
    "alpha_df.drop(other_list,inplace=True)\r\n",
    "\r\n",
    "alpha_df.to_csv(\"zz_data.csv\",index_label=\"code\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#行业中位数填充缺失值\r\n",
    "def median_fill(alpha_df,factor_list):\r\n",
    "    grouped = alpha_df.groupby(\"datetime\")\r\n",
    "    date_list = list(alpha_df[\"datetime\"].drop_duplicates())\r\n",
    "    filled_df = pd.DataFrame()\r\n",
    "\r\n",
    "    flag = 0\r\n",
    "\r\n",
    "    for date in date_list:\r\n",
    "        print(date,end=\" \")\r\n",
    "        panel_data = grouped.get_group(date)\r\n",
    "\r\n",
    "        df = pd.DataFrame(panel_data)\r\n",
    "\r\n",
    "        # 只留下需要处理的列\r\n",
    "        cols = factor_list\r\n",
    "        # 分组的列\r\n",
    "        gp_col = 'industry_code'\r\n",
    "        # 查询nan的列\r\n",
    "        df_na = df[cols].isnull()\r\n",
    "        # 根据分组计算中位数\r\n",
    "        df_median = df.groupby(gp_col)[cols].median()\r\n",
    "        # 依次处理每一列\r\n",
    "        for col in cols:\r\n",
    "            na_series = df_na[col]\r\n",
    "            names = list(df.loc[na_series, gp_col])\r\n",
    "\r\n",
    "            t = df_median.loc[names, col]\r\n",
    "            t.index = df.loc[na_series, col].index\r\n",
    "            t.fillna(t.mean(),inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "            # 相同的index进行赋值\r\n",
    "            df.loc[na_series, col] = t\r\n",
    "\r\n",
    "        if flag == 0:\r\n",
    "            filled_df = df\r\n",
    "            flag = 1\r\n",
    "        else:\r\n",
    "            filled_df = pd.concat([filled_df, df])\r\n",
    "\r\n",
    "\r\n",
    "    #filled_df.to_csv(\"filled_data.csv\", index=False, float_format=\"%.6f\")\r\n",
    "    return filled_df\r\n",
    "\r\n",
    "\r\n",
    "factor_list=['BETA','RSTR','LNCAP','ETOP','DASTD','EGRO','BTOP','DTOA','STOM']\r\n",
    "alpha_df=pd.read_csv(\"zz_data.csv\")\r\n",
    "df_1=median_fill(alpha_df,factor_list)\r\n",
    "\r\n",
    "\r\n",
    "#中位数极值法去除极端值\r\n",
    "def Median(alpha_df,factor_list):\r\n",
    "    date_list = list(alpha_df[\"datetime\"].drop_duplicates())\r\n",
    "    grouped = alpha_df.groupby(\"datetime\")\r\n",
    "\r\n",
    "    corrected_df = pd.DataFrame()\r\n",
    "    flag = 0\r\n",
    "\r\n",
    "    for date in date_list:\r\n",
    "        print(date,end=\" \")\r\n",
    "        try:\r\n",
    "            panel_data = grouped.get_group(date)\r\n",
    "        except:\r\n",
    "            continue\r\n",
    "        df = pd.DataFrame(panel_data)\r\n",
    "        colomn_names = factor_list\r\n",
    "        for colomn_name in colomn_names:\r\n",
    "            arr = np.array(df[colomn_name])\r\n",
    "            M = np.median(arr)\r\n",
    "            MAD = 1.483 * np.median(np.abs(arr - M))\r\n",
    "            arr[arr > M + 3 * MAD] = M + 3 * MAD\r\n",
    "            arr[arr < M - 3 * MAD] = M - 3 * MAD\r\n",
    "            df[colomn_name] = arr\r\n",
    "        if flag == 0:\r\n",
    "            flag = 1\r\n",
    "            corrected_df = df\r\n",
    "        else:\r\n",
    "            corrected_df = pd.concat([corrected_df, df])\r\n",
    "\r\n",
    "    #corrected_df.to_csv(\"median_mad.csv\", index=False)\r\n",
    "    return corrected_df\r\n",
    "\r\n",
    "alpha_df=df_1\r\n",
    "factor_list=['BETA','RSTR','LNCAP','ETOP','DASTD','EGRO','BTOP','DTOA','STOM']\r\n",
    "df_2=Median(alpha_df,factor_list)\r\n",
    "\r\n",
    "\r\n",
    "#Z_score法进行标准化\r\n",
    "def Z_score(alpha_df,factor_list):\r\n",
    "    date_list = list(alpha_df[\"datetime\"].drop_duplicates())\r\n",
    "    grouped = alpha_df.groupby(\"datetime\")\r\n",
    "    stddized_df = pd.DataFrame()\r\n",
    "    flag = 0\r\n",
    "\r\n",
    "    for date in date_list:\r\n",
    "        print(date,end=\" \")\r\n",
    "        try:\r\n",
    "            panel_data = grouped.get_group(date)\r\n",
    "        except:\r\n",
    "            continue\r\n",
    "        df = pd.DataFrame(panel_data)\r\n",
    "\r\n",
    "        colomn_names = factor_list\r\n",
    "        for colomn_name in colomn_names:\r\n",
    "            arr = np.array(df[colomn_name])\r\n",
    "            weight = np.array(len(arr) * [1 / len(arr)])\r\n",
    "            weighted_avarage = np.dot(weight.T, arr)\r\n",
    "            arr = (arr - weighted_avarage) / arr.std()\r\n",
    "            df[colomn_name] = arr\r\n",
    "        if flag == 0:\r\n",
    "            flag = 1\r\n",
    "            stddized_df = df\r\n",
    "        else:\r\n",
    "            stddized_df = pd.concat([stddized_df, df])\r\n",
    "\r\n",
    "    stddized_df.to_csv(\"equal_weight ZScore.csv\", index=False)\r\n",
    "\r\n",
    "\r\n",
    "factor_list=['BETA','RSTR','LNCAP','ETOP','DASTD','EGRO','BTOP','DTOA','STOM']\r\n",
    "alpha_df=df_2\r\n",
    "Z_score(alpha_df,factor_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#添加上股票的日频收益率数据\r\n",
    "zz_data=pd.read_csv(\"equal_weight ZScore.csv\")\r\n",
    "l=list(set(zz_data[\"code\"][zz_data[\"industry_code\"]==0]))\r\n",
    "zz_data.set_index(\"code\",inplace=True)\r\n",
    "zz_data.drop(l,inplace=True)\r\n",
    "zz_data.reset_index(inplace=True)\r\n",
    "\r\n",
    "change_data_1=pd.read_csv(\"change.csv\",dtype={\"stock_code\":str})\r\n",
    "change_data_2=pd.read_csv(\"change_2.csv\",dtype={\"stock_code\":str})\r\n",
    "change_data=pd.concat([change_data_1,change_data_2])\r\n",
    "\r\n",
    "change_data.rename(columns={\"stock_code\":\"code\",\"trade_date\":\"datetime\"},inplace=True)\r\n",
    "change_data[\"datetime\"]=change_data[\"datetime\"].apply(lambda x:x[0:10])\r\n",
    "change_data[\"code\"]=change_data[\"code\"].apply(lambda x:x+\".SH\" if x[0]==\"6\" else x+\".SZ\")\r\n",
    "zz_data_1=pd.merge(zz_data,change_data,\"left\",on=[\"code\",\"datetime\"])\r\n",
    "\r\n",
    "zz_data_1[\"change_rate\"].fillna(0,inplace=True)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#根据股票日频收益率计算出股票21天收益率以及年化21天平均收益\r\n",
    "def fun(df):\r\n",
    "    df=pd.DataFrame(df)\r\n",
    "    df.reset_index(inplace=True)\r\n",
    "    \r\n",
    "    df[\"ln_change\"]=np.log(1+df[\"change_rate\"]/100)\r\n",
    "    df[\"21d_ret\"]=(np.exp(pd.rolling_sum(df[\"ln_change\"],21))-1)*100\r\n",
    "    df[\"avg_ret\"]=pd.rolling_mean(df[\"21d_ret\"][::-1],200)[::-1].shift(-20)\r\n",
    "    \r\n",
    "    index=df[\"index\"]\r\n",
    "    new_df[\"avg_ret\"][index]=df[\"avg_ret\"]\r\n",
    "    new_df[\"21d_ret\"][index]=df[\"21d_ret\"]\r\n",
    "    print(\"finish\",end=\" \")\r\n",
    "    return 0\r\n",
    "\r\n",
    "new_df=pd.DataFrame(zz_data_1)\r\n",
    "new_df[\"21d_ret\"]=0\r\n",
    "new_df[\"avg_ret\"]=0\r\n",
    "zz_data_1.groupby(\"code\").apply(fun)\r\n",
    "\r\n",
    "new_df.to_csv(\"equal_weight ZScore.csv\",index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}