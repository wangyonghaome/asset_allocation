{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import statsmodels.api as sm\r\n",
    "import scipy.optimize as sco\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def zjh(arr):\r\n",
    "    arr_t=arr.transpose()\r\n",
    "\r\n",
    "    #计算重叠矩阵\r\n",
    "    overlap_matrix=np.dot(arr_t,arr)\r\n",
    "    overlap_matrix=(overlap_matrix.T+overlap_matrix)/2\r\n",
    "    #计算特征值、特征向量\r\n",
    "    eigvalue,eigvector=np.linalg.eig(overlap_matrix)\r\n",
    "\r\n",
    "    #处理对角矩阵\r\n",
    "    eigvalue=eigvalue**(-0.5)\r\n",
    "    DiagMat=np.diag(eigvalue)\r\n",
    "\r\n",
    "    #计算最终正交矩阵\r\n",
    "    tmp=np.dot(eigvector,DiagMat)\r\n",
    "    TSMat=np.dot(tmp,eigvector.transpose())\r\n",
    "    OrthMat=np.dot(arr,TSMat)\r\n",
    "    \r\n",
    "    return OrthMat\r\n",
    "\r\n",
    "def data_handle(mat):\r\n",
    "    for i in range(mat.shape[1]):\r\n",
    "        arr = np.array(mat[:,i])\r\n",
    "        M = np.median(arr)\r\n",
    "        MAD = 1.483 * np.median(np.abs(arr - M))\r\n",
    "        arr[arr > M + 3 * MAD] = M + 3 * MAD\r\n",
    "        arr[arr < M - 3 * MAD] = M - 3 * MAD\r\n",
    "        mat[:,i] = arr\r\n",
    "            \r\n",
    "    for i in range(mat.shape[1]):\r\n",
    "        arr = np.array(mat[:,i])\r\n",
    "        weight = np.array(len(arr) * [1 / len(arr)])\r\n",
    "        weighted_avarage = np.dot(weight.T, arr)\r\n",
    "        arr = (arr - weighted_avarage) / arr.std()\r\n",
    "        mat[:,i] = arr\r\n",
    "    return mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#数据处理\r\n",
    "change_data_1=pd.read_csv(\"change.csv\",dtype={\"stock_code\":str})\r\n",
    "change_data_2=pd.read_csv(\"change_2.csv\",dtype={\"stock_code\":str})\r\n",
    "change_data=pd.concat([change_data_1,change_data_2])\r\n",
    "\r\n",
    "change_data.rename(columns={\"stock_code\":\"code\",\"trade_date\":\"datetime\"},inplace=True)\r\n",
    "change_data[\"datetime\"]=change_data[\"datetime\"].apply(lambda x:x[0:10])\r\n",
    "change_data[\"code\"]=change_data[\"code\"].apply(lambda x:x+\".SH\" if x[0]==\"6\" else x+\".SZ\")\r\n",
    "\r\n",
    "change_data.sort_values(by=[\"datetime\",\"code\"],ascending=[True,True],inplace=True)\r\n",
    "\r\n",
    "change_data.set_index(\"code\",inplace=True)\r\n",
    "\r\n",
    "grouped=change_data.groupby(\"datetime\")\r\n",
    "date_list=list(change_data[\"datetime\"].drop_duplicates())\r\n",
    "code_list=list(change_data.index.drop_duplicates())\r\n",
    "join=set(code_list)\r\n",
    "union=set(code_list)\r\n",
    "for date in date_list:\r\n",
    "    df=grouped.get_group(date)\r\n",
    "    stock_set=set(df.index)\r\n",
    "    join=stock_set&join\r\n",
    "    union=stock_set|union\r\n",
    "other_list=list(union-join)\r\n",
    "change_data.drop(other_list,inplace=True)\r\n",
    "\r\n",
    "drop_list=random.sample(list(join),1135)\r\n",
    "change_data.drop(drop_list,inplace=True)\r\n",
    "\r\n",
    "change_data.reset_index(inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "data=pd.read_csv(\"data_needs.csv\")\r\n",
    "date=list(data[\"datetime\"].drop_duplicates())[-1]\r\n",
    "df=data.groupby(\"datetime\").get_group(date)\r\n",
    "dic=dict(zip(df[\"code\"],df[\"industry_code\"]))\r\n",
    "change_data[\"industry_code\"]=change_data[\"code\"].apply(lambda x:dic.get(x,0))\r\n",
    "\r\n",
    "drop_list=list(set(change_data[\"code\"][change_data[\"industry_code\"]==0]))\r\n",
    "change_data.set_index(\"code\",inplace=True)\r\n",
    "change_data.drop(drop_list,inplace=True)\r\n",
    "change_data.reset_index(inplace=True)\r\n",
    "\r\n",
    "stock_ret_df=change_data.pivot_table(\"change_rate\",index=\"datetime\",columns=\"code\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha_df=pd.read_csv(\"growth_factor.csv\")\r\n",
    "del alpha_df[\"industry_code\"]\r\n",
    "\r\n",
    "code_list=list(alpha_df[\"code\"].drop_duplicates())\r\n",
    "alpha_df.set_index(\"code\",inplace=True)\r\n",
    "\r\n",
    "drop_code=set(code_list)-set(stock_ret_df.columns)\r\n",
    "alpha_df.drop(drop_code,inplace=True)\r\n",
    "\r\n",
    "alpha_df.reset_index()\r\n",
    "\r\n",
    "alpha_df.sort_values(by=[\"datetime\",\"code\"],ascending=[True,True],inplace=True)\r\n",
    "\r\n",
    "alpha_df=pd.merge(alpha_df,change_data,on=[\"datetime\",\"code\"])\r\n",
    "alpha_df.fillna(0,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mcap_data_1=pd.read_csv(\"mcap.csv\",dtype={\"stock_code\":str})\r\n",
    "mcap_data_2=pd.read_csv(\"mcap_2.csv\",dtype={\"stock_code\":str})\r\n",
    "mcap_data=pd.concat([mcap_data_1,mcap_data_2])\r\n",
    "\r\n",
    "mcap_data.rename(columns={\"stock_code\":\"code\",\"trade_date\":\"datetime\"},inplace=True)\r\n",
    "mcap_data[\"datetime\"]=mcap_data[\"datetime\"].apply(lambda x:x[0:10])\r\n",
    "mcap_data[\"code\"]=mcap_data[\"code\"].apply(lambda x:x+\".SH\" if x[0]==\"6\" else x+\".SZ\")\r\n",
    "\r\n",
    "new_alpha_df=pd.merge(alpha_df,mcap_data,on=[\"datetime\",\"code\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ret_df=stock_ret_df\r\n",
    "\r\n",
    "for code in ret_df.columns:\r\n",
    "    ret_df[code+\"_In_change\"]=np.array(np.log(1+ret_df[code]/100))[::-1]\r\n",
    "    ret_df[code+\"_21d_ret\"]=(np.array(np.exp(ret_df[code+\"_In_change\"].rolling(21).apply(np.sum)))[::-1]-1)*100\r\n",
    "    ret_df[code+\"_21d_ret\"]=ret_df[code+\"_21d_ret\"].shift(-1)\r\n",
    "    del ret_df[code+\"_In_change\"]\r\n",
    "\r\n",
    "stock_num=len(stock_ret_df.columns)\r\n",
    "df=pd.DataFrame(stock_ret_df.iloc[:,int(stock_num/2):stock_num]).stack()\r\n",
    "\r\n",
    "df=df.reset_index()\r\n",
    "df[\"code\"]=df[\"code\"].apply(lambda x:x[0:9])\r\n",
    "new_alpha_df=pd.merge(new_alpha_df,df,on=[\"datetime\",\"code\"])\r\n",
    "new_alpha_df.rename(columns={0:\"21d_ret\"},inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "zz500=pd.read_csv(\"zz500.csv\")\r\n",
    "zz500[\"In_change\"]=np.array(np.log(1+zz500[\"change_rate\"]/100))[::-1]\r\n",
    "zz500[\"21d_ret\"]=(np.array(np.exp(zz500[\"In_change\"].rolling(21).apply(np.sum)))[::-1]-1)*100\r\n",
    "zz500[\"21d_ret\"]=zz500[\"21d_ret\"].shift(-1)\r\n",
    "\r\n",
    "\r\n",
    "zz500.rename(columns={\"21d_ret\":\"mkt_ret\",\"trade_date\":\"datetime\"},inplace=True)\r\n",
    "zz500[\"datetime\"]=zz500[\"datetime\"].apply(lambda x:x[0:10])\r\n",
    "del zz500[\"index_code\"]\r\n",
    "del zz500[\"In_change\"]\r\n",
    "del zz500[\"change_rate\"]\r\n",
    "new_alpha_df=pd.merge(new_alpha_df,zz500,on=\"datetime\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_alpha_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "date_list=list(new_alpha_df[\"datetime\"].drop_duplicates())\r\n",
    "code_list=list(new_alpha_df[\"code\"].drop_duplicates())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "date_list=date_list[:-21]\r\n",
    "factor_list=[\"EGRO\",\"EGIB\",\"EPIBS\",\"SGRO\"]\r\n",
    "factor_ret_df=pd.DataFrame(columns=factor_list,index=date_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha_df=new_alpha_df\r\n",
    "grouped=alpha_df.groupby(\"datetime\")\r\n",
    "\r\n",
    "for date in date_list:\r\n",
    "    df=grouped.get_group(date)\r\n",
    "\r\n",
    "    mktv=np.array(df[\"mcap\"])\r\n",
    "    mktv_pct=np.sqrt(mktv)/np.sum(np.sqrt(mktv))\r\n",
    "    weight=mktv_pct**(0.5)\r\n",
    "    \r\n",
    "    y=np.array(df[\"21d_ret\"]-df[\"mkt_ret\"])\r\n",
    "    y=np.dot(np.diag(weight),y)\r\n",
    "    \r\n",
    "    indus_factor=np.array(sm.categorical(np.array(df[\"industry_code\"])))[:, 1:]\r\n",
    "    style_factor=np.array(df[factor_list])\r\n",
    "    style_factor=data_handle(zjh(data_handle(style_factor)))\r\n",
    "    x=np.column_stack([style_factor,indus_factor])\r\n",
    "    x=np.dot(np.diag(weight),x)\r\n",
    "    \r\n",
    "    model=sm.OLS(y,x)\r\n",
    "    result=model.fit()\r\n",
    "    factor_ret=result.params[0:4]\r\n",
    "    factor_ret_df.loc[date]=factor_ret"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "factor_ret_df=pd.concat([factor_ret_df,pd.DataFrame(columns=range(12),index=date_list)],axis=1)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(251,len(date_list)-21):\r\n",
    "    window=range(i-251,i+1)\r\n",
    "    sub_df=factor_ret_df.iloc[window,0:4]\r\n",
    "    factor_ret_mean=np.array(sub_df.apply(np.mean,axis=0))\r\n",
    "    factor_ret_df.iloc[i+21,4:8]=np.abs(factor_ret_mean)/np.sum(np.abs(factor_ret_mean))\r\n",
    "    \r\n",
    "    factor_ret_std=np.array(sub_df.apply(np.std,axis=0))\r\n",
    "    factor_ret_df.iloc[i+21,8:12]=np.abs(factor_ret_std**-1)/np.sum(np.abs(factor_ret_std**-1))\r\n",
    "    \r\n",
    "    factor_ret_df.iloc[i+21,12:16]=np.array([0.18,0.11,0.24,0.47])\r\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "R_square_df=pd.DataFrame(index=date_list[272:len(date_list)-21],columns=[\"mean_weight\",\"var_weight\",\"fixed_weight\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for date in date_list[272:len(date_list)-21]:\r\n",
    "    print(date,end=\" \")\r\n",
    "    df=grouped.get_group(date)\r\n",
    "\r\n",
    "    mktv=np.array(df[\"mcap\"])\r\n",
    "    mktv_pct=np.sqrt(mktv)/np.sum(np.sqrt(mktv))\r\n",
    "    weight=mktv_pct**(0.5)\r\n",
    "    \r\n",
    "    y=np.array(df[\"21d_ret\"]-df[\"mkt_ret\"])\r\n",
    "    y=np.dot(np.diag(weight),y)\r\n",
    "    \r\n",
    "    indus_factor=np.array(sm.categorical(np.array(df[\"industry_code\"])))[:, 1:]\r\n",
    "    \r\n",
    "    \r\n",
    "    #因子收益率均值作为因子权重\r\n",
    "    style_factor=np.array(df[factor_list])\r\n",
    "    factor_weight=np.array(factor_ret_df.ix[date,4:8])\r\n",
    "    new_factor=np.dot(style_factor,factor_weight.T)\r\n",
    "    new_factor=data_handle(new_factor.reshape(len(new_factor),1))\r\n",
    "    x=np.column_stack([new_factor,indus_factor])\r\n",
    "    x=np.dot(np.diag(weight),x)\r\n",
    "    x=np.array(x,dtype=float)\r\n",
    "    \r\n",
    "    model=sm.OLS(y,x)\r\n",
    "    result=model.fit()\r\n",
    "    R_square=result.rsquared_adj\r\n",
    "    R_square_df.loc[date,\"mean_weight\"]=R_square\r\n",
    "    \r\n",
    "    \r\n",
    "    #因子收益率波动率倒数作为因子权重\r\n",
    "    style_factor=np.array(df[factor_list])\r\n",
    "    factor_weight=np.array(factor_ret_df.ix[date,8:12])\r\n",
    "    new_factor=np.dot(style_factor,factor_weight.T)\r\n",
    "    new_factor=data_handle(new_factor.reshape(len(new_factor),1))\r\n",
    "    x=np.column_stack([new_factor,indus_factor])\r\n",
    "    x=np.dot(np.diag(weight),x)\r\n",
    "    x=np.array(x,dtype=float)\r\n",
    "    \r\n",
    "    model=sm.OLS(y,x)\r\n",
    "    result=model.fit()\r\n",
    "    R_square=result.rsquared_adj\r\n",
    "    R_square_df.loc[date,\"var_weight\"]=R_square\r\n",
    "    \r\n",
    "    \r\n",
    "    #固定权重\r\n",
    "    style_factor=np.array(df[factor_list])\r\n",
    "    factor_weight=np.array(factor_ret_df.ix[date,12:16])\r\n",
    "    new_factor=np.dot(style_factor,factor_weight.T)\r\n",
    "    new_factor=data_handle(new_factor.reshape(len(new_factor),1))\r\n",
    "    x=np.column_stack([new_factor,indus_factor])\r\n",
    "    x=np.dot(np.diag(weight),x)\r\n",
    "    x=np.array(x,dtype=float)\r\n",
    "    \r\n",
    "    model=sm.OLS(y,x)\r\n",
    "    result=model.fit()\r\n",
    "    R_square=result.rsquared_adj\r\n",
    "    R_square_df.loc[date,\"fixed_weight\"]=R_square\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "R_square_df.mean(axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "R_square_df.index=pd.to_datetime(R_square_df.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = R_square_df.plot() \r\n",
    "fig = ax.get_figure()\r\n",
    "fig.savefig('R_square.jpg',dpi=500)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}